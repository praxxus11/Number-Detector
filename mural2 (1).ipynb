{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Big_project/mnist_test.csv', header=None)\n",
    "train_X = np.array(df.iloc[:9600, 1:]).astype(float)\n",
    "test_X = np.array(df.iloc[9600:, 1:]).astype(float)\n",
    "train_y = np.array(df.iloc[:9600, 0]).astype(float)\n",
    "test_y = np.array(df.iloc[9600:, 0]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers = (784, 25, 25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a list of numpy matrixes and returns a flattened version\n",
    "#theta in the parameter is a tuple of matrixes\n",
    "def flatten(theta):\n",
    "    if len(theta) == 0:\n",
    "        return np.array([])\n",
    "    else:\n",
    "        return np.concatenate((theta[0].flatten(), flatten(theta[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a flattened row of parameters and reshapes them in aaccordance\n",
    "#to the Layers global variable\n",
    "\n",
    "#Returns a list of the unflattened row\n",
    "def unflatten(theta):\n",
    "    param = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in range(0, len(Layers) - 1):\n",
    "        end += Layers[i+1] * (Layers[i] + 1)\n",
    "        param.append(theta[start:end].reshape(Layers[i+1], Layers[i] + 1))\n",
    "        start = end\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + pow(np.e, -z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddx_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_norm):\n",
    "    mean_std = []\n",
    "    X_copy = X_norm.copy()\n",
    "    for i in range(0, X_norm.shape[1]):\n",
    "        mean = np.mean(X_norm[:, i])\n",
    "        std = np.std(X_norm[:, i])\n",
    "        if std != 0:\n",
    "            X_copy[:, i] = (X_norm[:, i] - mean) / std\n",
    "            mean_std.append((mean, std))\n",
    "        else:\n",
    "            X_copy[:, i] = 0\n",
    "            mean_std.append((0, 1))\n",
    "    return X_copy, mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in the matrix of X values (m x n) and a vector of y values (m,) and \n",
    "# a flattened version of the parameters, a lambda_\n",
    "\n",
    "# returns the flattened gradient of the function at the current theta, \n",
    "# and also returns the cost of the function at that given location\n",
    "\n",
    "# a = [A1, A2, A3...AL]\n",
    "# z = [Z1, Z2, Z3...Z(L-1)]\n",
    "# d = [D2, D3...D(L-1)]\n",
    "\n",
    "def grad_and_cost(X, y, theta, lambda_=0):\n",
    "    J = 0\n",
    "    grads = []\n",
    "    \n",
    "    m = y.size\n",
    "    X = np.hstack((np.ones((m, 1)), X))\n",
    "    thetas = unflatten(theta)\n",
    "    for i in range(0, len(thetas)):\n",
    "        grads.append(np.zeros(thetas[i].shape))\n",
    "    for num in range(0, m):\n",
    "        vy = np.zeros(Layers[-1])\n",
    "        vy[int(y[num])] = 1\n",
    "        a = [X[num, :]]\n",
    "        z = []\n",
    "        #This is going through the thetas and setting the a and z values\n",
    "        #The size of z will be one less than the size of a\n",
    "        #Reason is because the first layer does not have a z value\n",
    "        for i in range(0, len(thetas)):\n",
    "            z.append(np.matmul(thetas[i], a[i]))\n",
    "            a_val = sigmoid(z[i])\n",
    "            if i != len(thetas) - 1:\n",
    "                a_val = np.hstack((1, a_val))\n",
    "            a.append(a_val)\n",
    "        \n",
    "        #Setting the values for delta, the error in each layer\n",
    "        #Like z, this one is one less element than a because\n",
    "        #the first layer is not included as a delta value\n",
    "        #(Because there is no 'error' for the predefined values)\n",
    "        d = [None] * (len(Layers) - 1)\n",
    "        for i in range(len(d) - 1, -1, -1):\n",
    "            if i == len(d) - 1:\n",
    "                d[i] = (a[i + 1] - vy)\n",
    "            else:\n",
    "                d[i] = np.matmul(thetas[i+1].T, d[i+1])[1:] * ddx_sigmoid(z[i])\n",
    "        \n",
    "        #Finally caluclating the gradients\n",
    "        for i in range(0, len(Layers) - 1):\n",
    "            #reshape (1, -1) broadcasts shape of vector (x,) to matrix (1, z)\n",
    "            grads[i] += np.matmul(d[i].reshape(-1, 1), (a[i].reshape(1, -1)))\n",
    "        #Finding the cost\n",
    "        J += sum(vy * np.log(a[-1]) + (1 - vy) * np.log(1 - a[-1]))\n",
    "    J /= -m\n",
    "    \n",
    "    #Adding on the regularization to both the cost and the gradient\n",
    "    reg = 0\n",
    "    for i in range(0, len(thetas)):\n",
    "        reg += np.sum(thetas[i][:, 1:] ** 2)\n",
    "        grads[i][:, 1:] += lambda_ * thetas[i][:, 1:]\n",
    "    reg *= lambda_ / (2 * m)\n",
    "    J += reg\n",
    "    fgrads = flatten(grads)\n",
    "    fgrads /= m\n",
    "    return fgrads, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS IS ONLY TO VERIFY GRADIENT IS CORRECT\n",
    "\n",
    "def get_cost(X, y, theta, lambda_=0):\n",
    "    tot = 0\n",
    "    m = y.size\n",
    "    X = np.hstack((np.ones((m, 1)), X))\n",
    "    thetas = unflatten(theta)\n",
    "    for num in range(0, m):\n",
    "        vy = np.zeros(Layers[-1])\n",
    "        vy[int(y[num])] = 1\n",
    "        a = [X[num, :]]\n",
    "        z = []\n",
    "        for i in range(0, len(thetas)):\n",
    "            z.append(np.matmul(thetas[i], a[i]))\n",
    "            a_val = sigmoid(z[i])\n",
    "            if i != len(thetas) - 1:\n",
    "                a_val = np.hstack((1, a_val))\n",
    "            a.append(a_val)\n",
    "        tot += sum(vy * np.log(a[-1]) + (1 - vy) * np.log(1 - a[-1]))\n",
    "    return tot / -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_prop(x, theta):\n",
    "    x = np.hstack((1, x))\n",
    "    thetas = unflatten(theta)\n",
    "    a = [x]\n",
    "    z = []\n",
    "    for i in range(0, len(thetas)):\n",
    "        z.append(np.matmul(thetas[i], a[i]))\n",
    "        a_val = sigmoid(z[i])\n",
    "        if i != len(thetas) - 1:\n",
    "            a_val = np.hstack((1, a_val))\n",
    "        a.append(a_val)\n",
    "    return a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f531072be80>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.arange(0, 500)\n",
    "Js = []\n",
    "the = np.random.uniform(-0.12, 0.12, (20535,))\n",
    "train_X, factors = normalize(train_X)\n",
    "for i in range(0, 500):\n",
    "    gra, J = grad_and_cost(train_X, train_y, the, 1.6)\n",
    "    the -= 1.8 * gra\n",
    "    Js.append(J)\n",
    "    if i % 20 == 0:\n",
    "        print(str(i))\n",
    "plt.plot(xx, Js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "tempx = test_X.copy()\n",
    "tempy = test_y.copy()\n",
    "for (i, fact) in zip(range(0, 784), factors):\n",
    "    if fact[1] != 0:\n",
    "        tempx[:, i] = (tempx[:, i] - fact[0]) / fact[1]\n",
    "    else:\n",
    "        tempx[:, i] = 0\n",
    "good = 0\n",
    "for i in range(0, tempx.shape[0]):\n",
    "    fr = front_prop(tempx[i, :], the)\n",
    "    if np.argmax(fr) == tempy[i] and np.max(fr) >= 0.5:\n",
    "        good += 1\n",
    "print(good / tempy.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(file):\n",
    "    img = np.array(Image.open(file).convert('L')).astype(float)\n",
    "    img = 255 - img\n",
    "    plt.imshow(img, cmap='Greys')\n",
    "    plt.clim()\n",
    "    plt.axis('off')\n",
    "    plt.rcParams['figure.figsize']=2, 2\n",
    "    \n",
    "    #flattens and normalizes the img to same parameters as the traning set\n",
    "    img = img.flatten()\n",
    "    for i in range(0, len(factors)):\n",
    "        if factors[i][1] != 0:\n",
    "            img[i] = (img[i] - factors[i][0]) / factors[i][1]\n",
    "        else:\n",
    "            img[i] = 0\n",
    "    pred = front_prop(img, the)\n",
    "    for i in range(0, len(pred)):\n",
    "        print(str(i) + \" : \" + str(round(pred[i]*100, 3)) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
